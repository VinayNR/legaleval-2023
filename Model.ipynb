{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3275c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flair==0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tabs to white spaces\n",
    "with open('ner_data/dev.txt') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "    \n",
    "new_lines = []\n",
    "for line in lines:\n",
    "    new_line = line.replace('\\t',' ')\n",
    "    new_lines.append(new_line)\n",
    "\n",
    "with open('ner_data/dev2.txt', 'w') as f:\n",
    "    for line in new_lines:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e179a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the new line characters\n",
    "with open('ner_data/dev2.txt') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "    \n",
    "new_lines = []\n",
    "for line in lines:\n",
    "    parts = line.split(' ')\n",
    "    if len(parts) > 1 and parts[0] == '':\n",
    "        continue\n",
    "    new_lines.append(line)\n",
    "\n",
    "with open('ner_data/dev3.txt', 'w') as f:\n",
    "    for line in new_lines:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ae6d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading custom training data\n",
    "from flair.embeddings import FlairEmbeddings\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "# defining columns\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "data_folder = 'ner_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6941f1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-13 13:14:27,993 Reading data from ner_data\n",
      "2022-12-13 13:14:28,000 Train: ner_data/train.txt\n",
      "2022-12-13 13:14:28,004 Dev: ner_data/dev.txt\n",
      "2022-12-13 13:14:28,005 Test: None\n"
     ]
    }
   ],
   "source": [
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns, train_file='train.txt', dev_file='dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6411a482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size of train : 9896, dev : 1074\n"
     ]
    }
   ],
   "source": [
    "print(f'Corpus size of train : {len(corpus.train)}, dev : {len(corpus.dev)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940e93af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"In The High Court Of Kerala At Ernakulam Crl Mc No . 1622 of 2006 ( ) 1 . T.R.Ajayan , S / O. O.Raman , ... Petitioner Vs 1 . M.Ravindran , ... Respondent 2 . Mrs. Nirmala Dinesh , W / O. Dinesh , For Petitioner : Sri . A.Kumar For Respondent : Smt . M.K.Pushpalatha The Hon'ble Mr. Justice P.R.Raman The Hon'ble Mr. Justice V.K.Mohanan Dated : 07/01/2008 O R D E R\"   [− Tokens: 76  − Token-Labels: \"In The High <B-COURT> Court <I-COURT> Of <I-COURT> Kerala <I-COURT> At <I-COURT> Ernakulam <I-COURT> Crl Mc No . 1622 of 2006 ( ) 1 . T.R.Ajayan <B-PETITIONER> , S / O. O.Raman , ... Petitioner Vs 1 . M.Ravindran <B-RESPONDENT> , ... Respondent 2 . Mrs. Nirmala <B-RESPONDENT> Dinesh <I-RESPONDENT> , W / O. Dinesh , For Petitioner : Sri . A.Kumar <B-LAWYER> For Respondent : Smt . M.K.Pushpalatha <B-LAWYER> The Hon'ble Mr. Justice P.R.Raman <B-JUDGE> The Hon'ble Mr. Justice V.K.Mohanan <B-JUDGE> Dated : 07/01/2008 O R D E R\"]\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "import operator\n",
    "\n",
    "label_dict = {}\n",
    "with open('ner_data/dev.txt') as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "    \n",
    "for line in lines:\n",
    "    parts = line.split(' ')\n",
    "    if len(parts) > 1 and parts[1].startswith('B'):\n",
    "        label_parts = parts[1].split('-')\n",
    "        if label_parts[1] not in label_dict:\n",
    "            label_dict[label_parts[1]] = 0\n",
    "        label_dict[label_parts[1]] += 1\n",
    "        \n",
    "print(label_dict)\n",
    "\n",
    "# sorted_label_dict = {k: v for k, v in sorted(label_dict.items(), key=lambda item: item[1])}\n",
    "sorted_label_dict = dict(sorted(label_dict.items(), key=operator.itemgetter(1),reverse=True))\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(sorted_label_dict)), list(sorted_label_dict.values()), align='center')\n",
    "plt.xticks(range(len(sorted_label_dict)), list(sorted_label_dict.keys()), rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f05bd522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-13 13:15:34,525 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 9896/9896 [00:02<00:00, 3671.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-13 13:15:37,324 Corpus contains the labels: ner (#549519)\n",
      "2022-12-13 13:15:37,328 Created (for label 'ner') Dictionary with 29 tags: O, B-COURT, I-COURT, B-PETITIONER, B-RESPONDENT, I-RESPONDENT, B-LAWYER, B-JUDGE, I-JUDGE, I-LAWYER, I-PETITIONER, B-ORG, I-ORG, B-WITNESS, I-WITNESS, B-GPE, B-OTHER_PERSON, I-OTHER_PERSON, B-DATE, I-DATE, B-PROVISION, I-PROVISION, B-STATUTE, I-STATUTE, B-PRECEDENT, I-PRECEDENT, B-CASE_NUMBER, I-CASE_NUMBER, I-GPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary with 29 tags: O, B-COURT, I-COURT, B-PETITIONER, B-RESPONDENT, I-RESPONDENT, B-LAWYER, B-JUDGE, I-JUDGE, I-LAWYER, I-PETITIONER, B-ORG, I-ORG, B-WITNESS, I-WITNESS, B-GPE, B-OTHER_PERSON, I-OTHER_PERSON, B-DATE, I-DATE, B-PROVISION, I-PROVISION, B-STATUTE, I-STATUTE, B-PRECEDENT, I-PRECEDENT, B-CASE_NUMBER, I-CASE_NUMBER, I-GPE\n"
     ]
    }
   ],
   "source": [
    "# custom training the model with the corpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "label_type = 'ner'\n",
    "\n",
    "# 3. make the label dictionary from the corpus\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
    "# tag_dictionary = corpus.make_tag_dictionary('ner')\n",
    "print(label_dict)\n",
    "# print(tag_dictionary)\n",
    "# print(xxx)\n",
    "\n",
    "# 4. initialize embedding stack with Flair and GloVe\n",
    "embedding_types = [\n",
    "    FlairEmbeddings('news-forward-fast')\n",
    "]\n",
    "\n",
    "# embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "embeddings = WordEmbeddings('glove')\n",
    "\n",
    "# # 5. initialize sequence tagger\n",
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type=label_type,\n",
    "                        use_crf=True,\n",
    "                        reproject_embeddings=False)\n",
    "\n",
    "# # 6. initialize trainer\n",
    "trainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29773035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<flair.trainers.trainer.ModelTrainer object at 0x7fa2593730d0>\n"
     ]
    }
   ],
   "source": [
    "print(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca52482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-13 13:16:08,190 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-13 13:16:08,196 Model: \"SequenceTagger(\n",
      "  (embeddings): WordEmbeddings('glove')\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=31, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2022-12-13 13:16:08,199 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-13 13:16:08,206 Corpus: \"Corpus: 9896 train + 1074 dev + 1100 test sentences\"\n",
      "2022-12-13 13:16:08,219 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-13 13:16:08,222 Parameters:\n",
      "2022-12-13 13:16:08,235  - learning_rate: \"0.1\"\n",
      "2022-12-13 13:16:08,246  - mini_batch_size: \"32\"\n",
      "2022-12-13 13:16:08,250  - patience: \"3\"\n",
      "2022-12-13 13:16:08,251  - anneal_factor: \"0.5\"\n",
      "2022-12-13 13:16:08,255  - max_epochs: \"1\"\n",
      "2022-12-13 13:16:08,262  - shuffle: \"True\"\n",
      "2022-12-13 13:16:08,275  - train_with_dev: \"False\"\n",
      "2022-12-13 13:16:08,296  - batch_growth_annealing: \"False\"\n",
      "2022-12-13 13:16:08,313 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-13 13:16:08,323 Model training base path: \"resources/taggers/legal-ner\"\n",
      "2022-12-13 13:16:08,325 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-13 13:16:08,328 Device: cpu\n",
      "2022-12-13 13:16:08,333 ----------------------------------------------------------------------------------------------------\n",
      "2022-12-13 13:16:08,335 Embeddings storage mode: cpu\n",
      "2022-12-13 13:16:08,340 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "trainer.train('resources/taggers/legal-ner',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bc320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
